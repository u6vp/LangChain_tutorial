{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：[【連載】LangChainの公式チュートリアルを1個ずつ地味に､地道にコツコツと【Basic編#1】](https://zenn.dev/chips0711/articles/f4ed8ac37eb3a8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 環境設定\n",
    "※ライブラリはlangchain v0.2系ではなく最新のv0.3系を使用したため参考サイトとはバージョンが異なる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.7\n",
      "Package                  Version\n",
      "------------------------ -----------\n",
      "aiohappyeyeballs         2.4.4\n",
      "aiohttp                  3.11.11\n",
      "aiosignal                1.3.2\n",
      "annotated-types          0.7.0\n",
      "anyio                    4.7.0\n",
      "asttokens                3.0.0\n",
      "async-timeout            4.0.3\n",
      "attrs                    24.3.0\n",
      "certifi                  2024.12.14\n",
      "charset-normalizer       3.4.1\n",
      "click                    8.1.8\n",
      "colorama                 0.4.6\n",
      "comm                     0.2.2\n",
      "debugpy                  1.8.11\n",
      "decorator                5.1.1\n",
      "distro                   1.9.0\n",
      "exceptiongroup           1.2.2\n",
      "executing                2.1.0\n",
      "fastapi                  0.115.6\n",
      "frozenlist               1.5.0\n",
      "greenlet                 3.1.1\n",
      "h11                      0.14.0\n",
      "httpcore                 1.0.7\n",
      "httpx                    0.27.2\n",
      "idna                     3.10\n",
      "ipykernel                6.29.5\n",
      "ipython                  8.31.0\n",
      "jedi                     0.19.2\n",
      "jiter                    0.8.2\n",
      "jsonpatch                1.33\n",
      "jsonpointer              3.0.0\n",
      "jupyter_client           8.6.3\n",
      "jupyter_core             5.7.2\n",
      "langchain                0.3.13\n",
      "langchain-core           0.3.28\n",
      "langchain-openai         0.2.14\n",
      "langchain-text-splitters 0.3.4\n",
      "langserve                0.3.0\n",
      "langsmith                0.2.6\n",
      "matplotlib-inline        0.1.7\n",
      "multidict                6.1.0\n",
      "nest-asyncio             1.6.0\n",
      "numpy                    1.26.4\n",
      "openai                   1.58.1\n",
      "orjson                   3.10.12\n",
      "packaging                24.2\n",
      "parso                    0.8.4\n",
      "pip                      24.3.1\n",
      "platformdirs             4.3.6\n",
      "prompt_toolkit           3.0.48\n",
      "propcache                0.2.1\n",
      "psutil                   6.1.1\n",
      "pure_eval                0.2.3\n",
      "pydantic                 2.10.4\n",
      "pydantic_core            2.27.2\n",
      "Pygments                 2.18.0\n",
      "python-dateutil          2.9.0.post0\n",
      "python-dotenv            1.0.1\n",
      "pywin32                  308\n",
      "PyYAML                   6.0.2\n",
      "pyzmq                    26.2.0\n",
      "regex                    2024.11.6\n",
      "requests                 2.32.3\n",
      "requests-toolbelt        1.0.0\n",
      "setuptools               63.2.0\n",
      "six                      1.17.0\n",
      "sniffio                  1.3.1\n",
      "SQLAlchemy               2.0.36\n",
      "sse-starlette            2.2.0\n",
      "stack-data               0.6.3\n",
      "starlette                0.41.3\n",
      "tenacity                 9.0.0\n",
      "tiktoken                 0.8.0\n",
      "tornado                  6.4.2\n",
      "tqdm                     4.67.1\n",
      "traitlets                5.14.3\n",
      "typing_extensions        4.12.2\n",
      "urllib3                  2.3.0\n",
      "uvicorn                  0.34.0\n",
      "wcwidth                  0.2.13\n",
      "yarl                     1.18.3\n"
     ]
    }
   ],
   "source": [
    "!python -V\n",
    "# !pip install ipykernel\n",
    "# !pip install langchain-openai==0.2.14 langchain==0.3.13 langserve==0.3.0 python-dotenv\n",
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 英語から日本語への翻訳\n",
    "17行目でcontentに指定した英語テキストを日本語に翻訳する  \n",
    "例：Hi! → こんにちは！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"content\": \"こんにちは！\",\n",
      "    \"additional_kwargs\": {\n",
      "        \"refusal\": null\n",
      "    },\n",
      "    \"response_metadata\": {\n",
      "        \"token_usage\": {\n",
      "            \"completion_tokens\": 2,\n",
      "            \"prompt_tokens\": 20,\n",
      "            \"total_tokens\": 22,\n",
      "            \"completion_tokens_details\": null,\n",
      "            \"prompt_tokens_details\": null\n",
      "        },\n",
      "        \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "        \"system_fingerprint\": \"fp_04751d0b65\",\n",
      "        \"prompt_filter_results\": [\n",
      "            {\n",
      "                \"prompt_index\": 0,\n",
      "                \"content_filter_results\": {\n",
      "                    \"hate\": {\n",
      "                        \"filtered\": false,\n",
      "                        \"severity\": \"safe\"\n",
      "                    },\n",
      "                    \"jailbreak\": {\n",
      "                        \"filtered\": false,\n",
      "                        \"detected\": false\n",
      "                    },\n",
      "                    \"self_harm\": {\n",
      "                        \"filtered\": false,\n",
      "                        \"severity\": \"safe\"\n",
      "                    },\n",
      "                    \"sexual\": {\n",
      "                        \"filtered\": false,\n",
      "                        \"severity\": \"safe\"\n",
      "                    },\n",
      "                    \"violence\": {\n",
      "                        \"filtered\": false,\n",
      "                        \"severity\": \"safe\"\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        ],\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"logprobs\": null,\n",
      "        \"content_filter_results\": {\n",
      "            \"hate\": {\n",
      "                \"filtered\": false,\n",
      "                \"severity\": \"safe\"\n",
      "            },\n",
      "            \"protected_material_code\": {\n",
      "                \"filtered\": false,\n",
      "                \"detected\": false\n",
      "            },\n",
      "            \"protected_material_text\": {\n",
      "                \"filtered\": false,\n",
      "                \"detected\": false\n",
      "            },\n",
      "            \"self_harm\": {\n",
      "                \"filtered\": false,\n",
      "                \"severity\": \"safe\"\n",
      "            },\n",
      "            \"sexual\": {\n",
      "                \"filtered\": false,\n",
      "                \"severity\": \"safe\"\n",
      "            },\n",
      "            \"violence\": {\n",
      "                \"filtered\": false,\n",
      "                \"severity\": \"safe\"\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"type\": \"ai\",\n",
      "    \"name\": null,\n",
      "    \"id\": \"run-f423514e-b6ff-4d79-9a8c-21c1bf8fa505-0\",\n",
      "    \"example\": false,\n",
      "    \"tool_calls\": [],\n",
      "    \"invalid_tool_calls\": [],\n",
      "    \"usage_metadata\": {\n",
      "        \"input_tokens\": 20,\n",
      "        \"output_tokens\": 2,\n",
      "        \"total_tokens\": 22,\n",
      "        \"input_token_details\": {},\n",
      "        \"output_token_details\": {}\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Azure OpenAIのGPT-4o miniモデルを使用してAzureChatOpenAIインスタンスを作成します。\n",
    "model = AzureChatOpenAI(\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT\"],\n",
    ")\n",
    "\n",
    "# 翻訳指示とユーザーからのメッセージを定義します。\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from English into Japanese\"),\n",
    "    HumanMessage(content=\"Hi!\"),\n",
    "]\n",
    "\n",
    "# # モデルにメッセージを渡して翻訳を実行します。\n",
    "response = model.invoke(messages)\n",
    "formated_response = json.dumps(response.__dict__, indent=4, ensure_ascii=False)\n",
    "print(formated_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OutputParserによるレスポンスの整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは！\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 出力を文字列として取得するためのOutputParserをインスタンス化します。\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# モデルからのレスポンスを文字列としてパースします。\n",
    "parsed_result = parser.invoke(response)\n",
    "print(parsed_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplatesの導入\n",
    "動的なプロンプトの生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='Translate the following into Japanese:', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# システムメッセージのテンプレートを定義します。\n",
    "system_template = \"Translate the following into {language}:\"\n",
    "\n",
    "# ユーザーからの入力とシステムメッセージを基にプロンプトテンプレートを作成します。\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    (\"user\", \"{text}\")\n",
    "])\n",
    "\n",
    "# テンプレートを使ってプロンプトをフォーマットします。\n",
    "input_data = {\"language\": \"Japanese\", \"text\": \"Hi!\"}\n",
    "formatted_prompt = prompt_template.invoke(input_data)\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain Expression Language (LCEL)\n",
    "LangChainのコンポーネントを宣言的にチェーンするための方法  \n",
    "\n",
    "##### LCELの主な特徴\n",
    " - ストリーミングサポート\n",
    " - 非同期サポート\n",
    " - 最適化された並列実行\n",
    " - リトライとフォールバック\n",
    " - 中間結果へのアクセス\n",
    " - 入力と出力のスキーマ\n",
    " - LangSmithとのシームレスなトレース"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LCELを使ったコンポーネントのチェーン化\n",
    "モデルの呼び出しから出力の取得までを一つの流れで処理できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは！\n"
     ]
    }
   ],
   "source": [
    "# プロンプトテンプレート、モデル、出力パーサーを組み合わせてチェーンを作成します。\n",
    "chain = prompt_template | model | parser\n",
    "\n",
    "# チェーンに入力を渡して結果を取得します。\n",
    "result = chain.invoke({\"language\": \"Japanese\", \"text\": \"Hi!\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangServeを使ったアプリケーションのデプロイ\n",
    " - LangServeを使用すると、LangChainのチェーンをREST APIとして簡単に提供できる  \n",
    " - LangServeは、FastAPIと統合されており、Pydanticを使用したデータバリデーションもサポートしている  \n",
    " - これにより、エンドポイントの入力と出力スキーマが自動的に推論され、すべてのAPIコールで強制されるため、エラーメッセージが豊富になる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### サーバーのセットアップ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ライブラリの追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サーバー用\n",
    "#!pip install fastapi==0.115.6 uvicorn==0.34.0\n",
    "# バージョン関連の問題解決用\n",
    "#!httpx==0.27.2 starlette==0.41.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### serve.pyを作成してサーバを起動しておく\n",
    " - [サーバーリンク](http://localhost:8000/chain)  \n",
    " - [APIの仕様やエンドポイントの詳細リンク](http://localhost:8000/docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"serve.py\n",
    "保存したディレクトリで「python serve.py」コマンドを実行\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from fastapi import FastAPI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langserve import add_routes\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# プロンプトテンプレート、モデル、出力パーサーを定義します。\n",
    "system_template = \"Translate the following into {language}:\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([(\"system\", system_template), (\"user\", \"{text}\")])\n",
    "model = AzureChatOpenAI(\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT\"],\n",
    ")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# チェーンを定義します。\n",
    "chain = prompt_template | model | parser\n",
    "\n",
    "# appの定義としてFastAPIアプリケーションのインスタンスを作成します。\n",
    "app = FastAPI(\n",
    "    title=\"LangChain Server\",\n",
    "    version=\"1.0\",\n",
    "    description=\"A simple API server using LangChain's Runnable interfaces\",\n",
    ")\n",
    "\n",
    "# チェーンをエンドポイントに追加します。\n",
    "add_routes(app, chain, path=\"/chain\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "\n",
    "    # サーバーを起動します。\n",
    "    uvicorn.run(app, host=\"localhost\", port=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### アプリケーションの利用例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### requestsライブラリでの例\n",
    " - Pythonのrequestsライブラリを使用して、エンドポイントにリクエストを送信"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': '今日は美しい日です。', 'metadata': {'run_id': '98192bbe-b728-4754-b080-5a45223b5ba6', 'feedback_tokens': []}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# APIエンドポイントに送信するデータ\n",
    "data = {\"language\": \"Japanese\", \"text\": \"Today is a beatuiful day.\"}\n",
    "\n",
    "# POSTリクエストを送信して結果を取得\n",
    "response = requests.post(\"http://localhost:8000/chain/invoke\", json={'input': data})\n",
    "\n",
    "# エラーチェック\n",
    "if response.status_code == 200:\n",
    "    print(response.json())\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### langserve.RemoteRunnableクライアントでの例\n",
    " - langserveのRemoteRunnableを使用して、エンドポイントにリクエストを送信  \n",
    "→ httpxライブラリの問題？で動作せず・・・"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'VerifyTypes' from 'httpx._types' (c:\\Users\\naohiro\\Desktop\\desktop_memo\\program\\LangChain_tutorial\\.venv\\lib\\site-packages\\httpx\\_types.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangserve\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RemoteRunnable\n\u001b[0;32m      3\u001b[0m remote_chain \u001b[38;5;241m=\u001b[39m RemoteRunnable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://localhost:8000/chain/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m remote_chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJapanese\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToday is a beautiful day.\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "File \u001b[1;32mc:\\Users\\naohiro\\Desktop\\desktop_memo\\program\\LangChain_tutorial\\.venv\\lib\\site-packages\\langserve\\__init__.py:8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Main entrypoint into package.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mThis is the ONLY public interface into the package. All other modules are\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mto be considered private and subject to change without notice.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangserve\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_handler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m APIHandler\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangserve\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RemoteRunnable\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangserve\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CustomUserType\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangserve\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m add_routes\n",
      "File \u001b[1;32mc:\\Users\\naohiro\\Desktop\\desktop_memo\\program\\LangChain_tutorial\\.venv\\lib\\site-packages\\langserve\\client.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m urljoin\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhttpx\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhttpx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AuthTypes, CertTypes, CookieTypes, HeaderTypes, VerifyTypes\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     26\u001b[0m     AsyncCallbackManagerForChainRun,\n\u001b[0;32m     27\u001b[0m     CallbackManagerForChainRun,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdump\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dumpd\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'VerifyTypes' from 'httpx._types' (c:\\Users\\naohiro\\Desktop\\desktop_memo\\program\\LangChain_tutorial\\.venv\\lib\\site-packages\\httpx\\_types.py)"
     ]
    }
   ],
   "source": [
    "from langserve import RemoteRunnable\n",
    "\n",
    "remote_chain = RemoteRunnable(\"http://localhost:8000/chain/\")\n",
    "remote_chain.invoke({\"language\": \"Japanese\", \"text\": \"Today is a beautiful day.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LangServe組み込みのUIでの例\n",
    " - [WEB UI](http://localhost:8000/chain/playground/)からのAPI実行も可能"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
