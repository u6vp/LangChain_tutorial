{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：[【連載】LangChainの公式チュートリアルを1個ずつ地味に、地道にコツコツと【Basic編#2】](https://zenn.dev/chips0711/articles/0dd345d6c1e118)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基本的なチャットモデルの使用方法\n",
    "\n",
    " - メッセージの送信とそれに対するAIの応答実施例  \n",
    "User「こんにちは!わたしはボブです!」  \n",
    "AI「こんにちは、ボブさん！お元気ですか？今日はどんなことをお話ししましょうか？」  \n",
    " - この段階では、モデルは会話の状態を持たず、独立したメッセージに対してのみ応答を返す  \n",
    "\n",
    "※参考サイトでは環境変数名が間違っているため、修正必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは、ボブさん！お元気ですか？今日はどんなことをお話ししましょうか？\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 環境変数を設定します\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# AzureChatOpenAIインスタンスを作成します\n",
    "model = AzureChatOpenAI(\n",
    "    model=os.environ[\"AZURE_OPENAI_MODEL_NAME\"],\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT\"],\n",
    "    api_version=os.environ[\"OPENAI_API_VERSION\"],\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "# シンプルなメッセージをモデルに渡してみましょう\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "response = model.invoke([HumanMessage(content=\"こんにちわ!わたしはボブです!\")])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 会話履歴の管理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ライブラリの追加インポート必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain_community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RunnableWithMessageHistory クラスの使用方法\n",
    "RunnableWithMessageHistoryクラスは、別のRunnableオブジェクト（この場合は言語モデル）をラップし、そのチャットメッセージの履歴を管理する。  \n",
    "具体的な動作は以下の通り：\n",
    "\n",
    "1. 会話の前に、過去のメッセージをRunnableに渡す前にロード\n",
    "2. 実行後に生成された応答をメッセージとして保存\n",
    "3. session_idを使って複数の会話を管理し、呼び出し時にconfigでsession_idを指定して該当する会話履歴を読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SQLiteを使用してメッセージ履歴を管理する例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは、ボブさん！再びお会いできて嬉しいです。今日はどんなことをお話ししましょうか？\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "\n",
    "# セッションIDに基づいて履歴を取得する関数を定義します\n",
    "def get_session_history(session_id):\n",
    "    return SQLChatMessageHistory(session_id, connection=\"sqlite:///memory.db\")\n",
    "\n",
    "# メッセージ履歴を持つチャットボットを作成します\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    model,\n",
    "    get_session_history,\n",
    ")\n",
    "\n",
    "# コンフィグを設定し、チャットボットにメッセージを送信します\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"こんにちは！私はボブです。\")],\n",
    "    config={\"configurable\": {\"session_id\": \"1\"}},\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "あなたの名前はボブさんです。何か他にお話ししたいことがありますか？\n"
     ]
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"私の名前は何ですか？\")],\n",
    "    config={\"configurable\": {\"session_id\": \"1\"}},\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プロンプトテンプレートの追加"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - プロンプトテンプレートは、ユーザーからの入力を特定のフォーマットに変換することで、LLMが処理しやすい形式に整えるためのもの\n",
    " - ChatPromptTemplateを使用することで、システムメッセージとユーザーメッセージを組み合わせた柔軟なプロンプトを作成できる\n",
    " - 以下のコードでは、システムメッセージを使って、チャットボットに「役立つアシスタント」としての役割を指示している\n",
    "   - MessagesPlaceholderは、会話履歴を挿入する場所を指定するために使用されている\n",
    "   - これにより、過去の会話コンテキストを保持しながら、新しい入力に対応することができる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは、ボブさん！お会いできて嬉しいです。今日はどんなことをお手伝いできますか？\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# プロンプトテンプレートを作成します\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"あなたは役に立つアシスタントです。全ての質問に対してできる限りの答えをしてください。\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# チェーンを作成し、メッセージを送信します\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\"messages\": [HumanMessage(content=\"こんにちは！私はボブです。\")]})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多言語対応のチャットボット\n",
    " - ユーザーが選択した言語で応答するようにチャットボットを設定\n",
    " - NOTE: メッセージ送信の間隔が狭いと待ちがあるようで、実行に時間がかかる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola, Bob! ¿Cómo estás?\n"
     ]
    }
   ],
   "source": [
    "# 多言語対応のプロンプトテンプレートを作成します\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"あなたは役に立つアシスタントです。全ての質問に対して{language}で答えてください。\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# チェーンを作成し、メッセージを送信します\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"こんにちは！私はボブです。\")], \"language\": \"スペイン語\"}\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### カスタマイズオプション\n",
    " - ConfigurableFieldSpecを使用して、user_idとconversation_idの2つのパラメータで会話履歴を管理する方法\n",
    " - 同じユーザーIDであれば過去の会話履歴を保持し、新しいユーザーIDであれば新しい会話履歴が始まる\n",
    " - 複数のユーザーとの会話を個別に管理しつつ、言語設定も柔軟に変更できる高度なチャットボットシステムを構築できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao Bob! Come posso aiutarti oggi?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import ConfigurableFieldSpec\n",
    "\n",
    "# プロンプトテンプレートを作成します\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"あなたは役に立つアシスタントです。全ての質問に対して{language}でできる限りの答えをしてください。\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# プロンプトテンプレートとモデルを組み合わせたランナブルを作成します\n",
    "runnable_with_prompt = prompt | model | StrOutputParser()\n",
    "\n",
    "# セッションIDに基づいて履歴を取得する関数を定義します\n",
    "def get_session_history(user_id: str, conversation_id: str):\n",
    "    return SQLChatMessageHistory(f\"{user_id}--{conversation_id}\", connection=\"sqlite:///memory.db\")\n",
    "\n",
    "# メッセージ履歴を持つチャットボットを作成します\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    runnable_with_prompt,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    "    history_messages_key=\"history\",\n",
    "    history_factory_config=[\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"user_id\",\n",
    "            annotation=str,\n",
    "            name=\"ユーザーID\",\n",
    "            description=\"ユーザーのユニークな識別子。\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"conversation_id\",\n",
    "            annotation=str,\n",
    "            name=\"会話ID\",\n",
    "            description=\"会話のユニークな識別子。\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 正しい形式の入力メッセージと設定を行います\n",
    "input_message = [HumanMessage(content=\"こんにちは！私はボブです。\")]\n",
    "\n",
    "# メッセージを送信して応答を取得します\n",
    "response = with_message_history.invoke(\n",
    "    {\"language\": \"イタリア語\", \"messages\": input_message},  \n",
    "    config={\"configurable\": {\"user_id\": \"123\", \"conversation_id\": \"1\"}},\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "日本語で名前を覚えているか確認\n",
    "→　覚えていない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "申し訳ありませんが、あなたの名前を知ることはできません。名前を教えていただければ、その名前でお呼びすることができますよ。\n"
     ]
    }
   ],
   "source": [
    "# 正しい形式の入力メッセージと設定を行います\n",
    "input_message = [HumanMessage(content=\"私の名前は何ですか？\")]\n",
    "\n",
    "# メッセージを送信して応答を取得します\n",
    "response = with_message_history.invoke(\n",
    "    {\"language\": \"日本語\", \"messages\": input_message},  \n",
    "    config={\"configurable\": {\"user_id\": \"123\", \"conversation_id\": \"1\"}},\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "日本語で再度メッセージを送信"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは、ボブさん！お会いできて嬉しいです。今日はどんなことについてお話ししましょうか？\n"
     ]
    }
   ],
   "source": [
    "# 正しい形式の入力メッセージと設定を行います\n",
    "input_message = [HumanMessage(content=\"こんにちは！私はボブです。\")]\n",
    "\n",
    "# メッセージを送信して応答を取得します\n",
    "response = with_message_history.invoke(\n",
    "    {\"language\": \"日本語\", \"messages\": input_message},  \n",
    "    config={\"configurable\": {\"user_id\": \"123\", \"conversation_id\": \"1\"}},\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再度、日本語で名前を覚えているか確認　→　記憶できていない・・・  \n",
    "session_idでの履歴管理は出来ていたが何故？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "申し訳ありませんが、あなたの名前はわかりません。お名前を教えていただければ、何かお手伝いできるかもしれません。\n"
     ]
    }
   ],
   "source": [
    "# 正しい形式の入力メッセージと設定を行います\n",
    "input_message = [HumanMessage(content=\"私の名前は何ですか？\")]\n",
    "\n",
    "# メッセージを送信して応答を取得します\n",
    "response = with_message_history.invoke(\n",
    "    {\"language\": \"日本語\", \"messages\": input_message},  \n",
    "    config={\"configurable\": {\"user_id\": \"123\", \"conversation_id\": \"1\"}},\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "申し訳ありませんが、あなたの名前はわかりません。私に名前を教えていただければ、呼び方を工夫することができますよ！\n"
     ]
    }
   ],
   "source": [
    "# 正しい形式の入力メッセージと設定を行います\n",
    "input_message = [HumanMessage(content=\"私の名前は何ですか？\")]\n",
    "\n",
    "# メッセージを送信して応答を取得します\n",
    "response = with_message_history.invoke(\n",
    "    {\"language\": \"日本語\", \"messages\": input_message},  \n",
    "    config={\"configurable\": {\"user_id\": \"123\", \"conversation_id\": \"2\"}},\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 会話履歴の管理と最適化\n",
    " - チャットボットを長期間運用する場合、会話履歴が無限に増え続けると、LLMのコンテキストウィンドウを超えてしまい、効率的な応答ができなくなる可能性がある\n",
    " - LangChainには、会話履歴のサイズを適切に制限するためのツールが用意されている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### メッセージ履歴のトリミング\n",
    " - trim_messages ユーティリティを使用すると、指定されたトークン数に合わせて履歴をトリミングできる\n",
    " - これにより、モデルのコンテキストウィンドウ内に収まるようにメッセージの長さを調整できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='あなたは優秀なアシスタントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='ありがとう。', additional_kwargs={}, response_metadata={}), AIMessage(content='どういたしまして！', additional_kwargs={}, response_metadata={}), HumanMessage(content='楽しんでますか？', additional_kwargs={}, response_metadata={}), AIMessage(content='はい！', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, trim_messages\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "# トリミング設定を作成します\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=65,\n",
    "    strategy=\"last\",\n",
    "    token_counter=AzureChatOpenAI(model=\"gpt-4o\"),\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    ")\n",
    "\n",
    "# メッセージリストを定義します\n",
    "messages = [\n",
    "    SystemMessage(content=\"あなたは優秀なアシスタントです。\"),\n",
    "    HumanMessage(content=\"こんにちは！私はボブです。\"),\n",
    "    AIMessage(content=\"こんにちは！\"),\n",
    "    HumanMessage(content=\"私はバニラアイスクリームが好きです。\"),\n",
    "    AIMessage(content=\"いいですね。\"),\n",
    "    HumanMessage(content=\"2 + 2は何ですか？\"),\n",
    "    AIMessage(content=\"4です。\"),\n",
    "    HumanMessage(content=\"ありがとう。\"),\n",
    "    AIMessage(content=\"どういたしまして！\"),\n",
    "    HumanMessage(content=\"楽しんでますか？\"),\n",
    "    AIMessage(content=\"はい！\"),\n",
    "]\n",
    "\n",
    "# メッセージ履歴をトリミングします\n",
    "trimmed_messages = trimmer.invoke(messages)\n",
    "print(trimmed_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 以下はトリミングされた履歴を使ってプロンプトにメッセージを渡す例\n",
    " - 結果を見ると、チャットボットは名前を知らないと正直に答えている\n",
    " - これは、トリミングによって以前の会話（名前の紹介を含む）が削除されたため"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed messages:\n",
      "system: あなたは優秀なアシスタントです。\n",
      "human: ありがとう。\n",
      "ai: どういたしまして！\n",
      "human: 楽しんでますか？\n",
      "ai: はい！\n",
      "human: 私の名前は何ですか？\n",
      "\n",
      "Response:\n",
      "申し訳ありませんが、あなたの名前はわかりません。あなたの名前を教えていただければ、その名前でお呼びすることができます。\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# プロンプトテンプレートを定義します\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"あなたは役に立つアシスタントです。\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# トリミング結果を表示する関数\n",
    "def print_trimmed(messages):\n",
    "    print(\"Trimmed messages:\")\n",
    "    for msg in messages:\n",
    "        print(f\"{msg.type}: {msg.content}\")\n",
    "    return messages\n",
    "\n",
    "# メッセージ履歴をトリミングしてからプロンプトに渡すチェーンを作成します\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer | print_trimmed)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "# 入力メッセージを作成\n",
    "input_messages = messages + [HumanMessage(content=\"私の名前は何ですか？\")]\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": input_messages,\n",
    "        \"question\": \"私の名前は何ですか？\",\n",
    "        \"language\": \"日本語\",\n",
    "    }\n",
    ")\n",
    "print(\"\\nResponse:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trimmerの設定を変えたらどうか  \n",
    "→　やはりメモリ機能が効いていない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed messages:\n",
      "human: こんにちは！私はボブです。\n",
      "ai: こんにちは！\n",
      "human: 私はバニラアイスクリームが好きです。\n",
      "ai: いいですね。\n",
      "human: 2 + 2は何ですか？\n",
      "ai: 4です。\n",
      "\n",
      "Response:\n",
      "申し訳ありませんが、あなたの名前はわかりません。あなたの名前を教えていただければ、それに基づいてお話しすることができますよ。\n"
     ]
    }
   ],
   "source": [
    "# 古い履歴を残すトリミング設定を作成\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=65,\n",
    "    strategy=\"first\",\n",
    "    token_counter=AzureChatOpenAI(model=\"gpt-4o\"),\n",
    "    # include_system=False,\n",
    "    allow_partial=False,\n",
    "    # start_on=\"human\",\n",
    ")\n",
    "\n",
    "# メッセージ履歴をトリミングしてからプロンプトに渡すチェーンを作成します\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer | print_trimmed)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "# 入力メッセージを作成\n",
    "input_messages = messages[1:] + [HumanMessage(content=\"私の名前は何ですか？\")]\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": input_messages,\n",
    "        \"question\": \"私の名前は何ですか？\",\n",
    "        \"language\": \"日本語\",\n",
    "    }\n",
    ")\n",
    "print(\"\\nResponse:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### チャット履歴とトリミングの組み合わせ\n",
    " - RunnableWithMessageHistoryを使って、トリミングされたメッセージ履歴を管理する方法\n",
    " - ユーザーとの会話履歴を保持しつつ、適切にトリミングされたデータのみをプロンプトに渡すことができる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "喋れないオウムは「無口のオウム」や「黙ったオウム」と呼ぶことができます。また、あなたの名前はボブですね！他に知りたいことがあれば教えてください。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# プロンプトテンプレートの作成\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"あなたは役に立つアシスタントです。全ての質問に対して{language}で答えてください。\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# チェーンの作成\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(history=lambda x: x[\"history\"])\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# チャット履歴の初期化\n",
    "messages = [\n",
    "    SystemMessage(content=\"あなたは優秀なアシスタントです。\"),\n",
    "    HumanMessage(content=\"こんにちは！私はボブです。\"),\n",
    "    AIMessage(content=\"こんにちは、ボブさん！お手伝いできることがありますか？\"),\n",
    "]\n",
    "chat_history = InMemoryChatMessageHistory(messages=messages)\n",
    "\n",
    "# セッションIDに基づいて履歴を取得するダミー関数を定義\n",
    "def dummy_get_session_history(session_id):\n",
    "    if session_id != \"1\":\n",
    "        return InMemoryChatMessageHistory()\n",
    "    return chat_history\n",
    "\n",
    "# トリミングされたメッセージ履歴を持つチェーンを作成\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    dummy_get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "# メッセージを送信して応答を取得\n",
    "response = chain_with_history.invoke(\n",
    "    {\n",
    "        \"input\": \"喋れないオウムを何と呼びますか？また､私の名前はなんですか?\",\n",
    "        \"language\": \"日本語\"\n",
    "    },\n",
    "    config={\"configurable\": {\"session_id\": \"1\"}},\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "セッションIDを変更してみる  \n",
    "→　新しいセッションIDでは、以前の会話履歴（ボブさんの名前を含む）にアクセスできていないことがわかる  \n",
    "　　これは、会話履歴が適切にセッションごとに分離されていることを示している\n",
    "\n",
    "メモリ周りの動作参考サイト\n",
    " - [LangChain の Memory の概要 ](https://note.com/npaka/n/nbd04bdc041cb)\n",
    " - [LCEL記法のChainにMemoryを組み込む方法](https://zenn.dev/mizunny/articles/d974720d8acc6f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "喋れないオウムは「無口のオウム」や「黙っているオウム」と呼ぶことができます。また、あなたの名前については、私には分かりません。もし教えていただければ、その名前でお呼びすることができます。\n"
     ]
    }
   ],
   "source": [
    "response = chain_with_history.invoke(\n",
    "    {\n",
    "        \"input\": \"喋れないオウムを何と呼びますか？また､私の名前はなんですか?\",\n",
    "        \"language\": \"日本語\"\n",
    "    },\n",
    "    config={\"configurable\": {\"session_id\": \"2\"}},\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ストリーミングの導入\n",
    " - リアルタイムで生成されるトークンを見ることができ、よりスムーズなインタラクションを可能とする機能\n",
    " - ユーザーは応答の完了を待つことなく、途中経過を確認できる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. 同期的なストリーミング（stream メソッド）\n",
    " - 常のPythonコードで使用する\n",
    " - 以下のコードでは、chain_with_history.streamメソッドを使用して、チャットモデルからのストリーミング応答を逐次取得している\n",
    " - 実際のアプリケーションでは、end=\"|\" を end=\"\" に変更することで、ユーザーにはスムーズな文字の流れとして表示される \n",
    " - ここでは、ストリーミングの過程を可視化するために | で区切って表示している。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||こんにちは|、|ト|ッド|さん|！|ジョ|ーク|を|一|つ|お|教|え|します|ね|。\n",
      "\n",
      "|「|カ|メ|と|ウ|サ|ギ|が|レ|ース|を|しました|。|カ|メ|は|遅|い|け|ど|、|ウ|サ|ギ|は|早|く|走|り|す|ぎ|て|寝|ちゃ|った|。|カ|メ|が|勝|った|ん|だけ|ど|、|ウ|サ|ギ|は|こう|言|いました|。\n",
      "|『|次|は|寝|ない|よう|に|する|よ|！|』|」\n",
      "\n",
      "|どう|でした|か|？|笑|って|いただ|け|た|ら|嬉|しい|です|！||\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"session_id\": \"abc15\",\n",
    "        \"user_id\": \"user123\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# ストリーミング応答を取得します\n",
    "for r in chain_with_history.stream(\n",
    "    {\n",
    "        \"input\": \"こんにちは！私はトッドです。ジョークを教えてください\",\n",
    "        \"language\": \"日本語\",\n",
    "    },\n",
    "    config=config,\n",
    "):\n",
    "    print(r, end=\"|\", flush=True)\n",
    "print()  # 最後に改行を入れる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.非同期ストリーミング（astream メソッド）\n",
    " - asyncioなどの非同期プログラミング環境で使用する\n",
    " - Webアプリケーションなど、非同期処理が必要な環境で特に有用\n",
    " - 他の非同期タスクと並行して効率的に処理を行うことができる\n",
    " - 参考サイトのコードそのままでは非同期処理の実行でエラーでるため注意\n",
    "   - await関数で直接実行すれば問題なく動作([参考](https://qiita.com/osorezugoing/items/d26921f0affd62b87858))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||もちろん|です|！|こん|な|猫|の|ジョ|ーク|はい|か|が|です|か|？\n",
      "\n",
      "|「|猫|が|コン|ピ|ュー|ター|を|使|う|と|き|、|何|を|最|初|に|する|と思|います|か|？」\n",
      "\n",
      "|「|マ|ウ|ス|を|捕|ま|える|こと|！」| \n",
      "\n",
      "|どう|でした|か|？|少|し|笑|って|いただ|け|た|ら|嬉|しい|です|！||\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def get_streaming_response():\n",
    "    async for r in chain_with_history.astream(\n",
    "        {\n",
    "            \"input\": \"別のジョークを教えてください。今度は猫に関するものをお願いします。\",\n",
    "            \"language\": \"日本語\",\n",
    "        },\n",
    "        config=config,\n",
    "    ):\n",
    "        print(r, end=\"|\", flush=True)\n",
    "    print()  # 最後に改行を入れる\n",
    "\n",
    "# 非同期関数を実行\n",
    "# asyncio.run(get_streaming_response()) # NOTE:asyncio.run() cannot be called from a running event loop\n",
    "await get_streaming_response()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### エラーハンドリング\n",
    " - 以下は、try-exceptブロックを使用してエラーをキャッチする例\n",
    " - ストリーミング中にエラーが発生しても、プログラムが予期せず停止することを防ぐ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "プログラミングに関する面白い事実の一つは、最初のプログラマーとされるアダ・ラブレス（Ada Lovelace）です。彼女は1830年代にチャールズ・バベッジの解析機関（Analytical Engine）に関するノートを作成し、その中で初めてコンピュータプログラムを書いたとされています。ラブレスは、計算機が単なる計算以上のことを実行できる可能性を見出し、後のコンピュータ科学に大きな影響を与えました。\n",
      "\n",
      "さらに、彼女の名前を冠したプログラミング言語「Ada」も存在します。これは、航空宇宙や軍事などの分野で広く使用されている高級言語です。アダ・ラブレスの存在は、女性がテクノロジーの分野で果たす重要な役割を示す象徴的な例でもあります。\n"
     ]
    }
   ],
   "source": [
    "async def handle_streaming_response():\n",
    "    try:\n",
    "        async for r in chain_with_history.astream(\n",
    "            {\n",
    "                \"input\": \"プログラミングに関する面白い事実を教えてください\",\n",
    "                \"language\": \"日本語\",\n",
    "            },\n",
    "            config=config,\n",
    "        ):\n",
    "            print(r, end=\"\", flush=True)\n",
    "        print()  # 最後に改行を入れる\n",
    "    except Exception as e:\n",
    "        print(f\"エラーが発生しました: {e}\")\n",
    "\n",
    "await handle_streaming_response()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
